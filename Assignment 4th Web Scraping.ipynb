{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[28]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>7.39</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[30]</td>\n",
       "      <td>Luis Fonsi featuring Daddy Yankee</td>\n",
       "      <td>7.09</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Shape of You\"[31]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.10</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"See You Again\"[32]</td>\n",
       "      <td>Wiz Khalifa featuring Charlie Puth</td>\n",
       "      <td>4.85</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.38</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[36]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>4.37</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Uptown Funk\"[37]</td>\n",
       "      <td>Mark Ronson featuring Bruno Mars</td>\n",
       "      <td>4.03</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Gangnam Style\"[38]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>3.88</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[40]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>3.66</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Sorry\"[41]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.37</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Bath Song\"[42]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.34</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Sugar\"[43]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.34</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[44]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>3.30</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Roar\"[45]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.22</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.13</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[47]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.13</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Shake It Off\"[48]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>2.99</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Dame Tu Cosita\"[49]</td>\n",
       "      <td>El Chombo featuring Cutty Ranks</td>\n",
       "      <td>2.94</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Bailando\"[50]</td>\n",
       "      <td>Enrique Iglesias featuring Descemer Bueno and ...</td>\n",
       "      <td>2.94</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Lean On\"[51]</td>\n",
       "      <td>Major Lazer and DJ Snake featuring MØ</td>\n",
       "      <td>2.93</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Faded\"[52]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>2.92</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[53]</td>\n",
       "      <td>Katy Perry featuring Juicy J</td>\n",
       "      <td>2.92</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>Maroon 5 featuring Cardi B</td>\n",
       "      <td>2.91</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[55]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>2.85</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Mi Gente\"[56]</td>\n",
       "      <td>J Balvin and Willy William</td>\n",
       "      <td>2.82</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Hello\"[57]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>2.75</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Blank Space\"[58]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>2.68</td>\n",
       "      <td>November 10, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[59]</td>\n",
       "      <td>Shakira featuring Freshlyground</td>\n",
       "      <td>2.66</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Perfect\"[60]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>2.65</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Chantaje\"[61]</td>\n",
       "      <td>Shakira featuring Maluma</td>\n",
       "      <td>2.60</td>\n",
       "      <td>November 18, 2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                           \"Baby Shark Dance\"[28]   \n",
       "1    2.                                  \"Despacito\"[30]   \n",
       "2    3.                               \"Shape of You\"[31]   \n",
       "3    4.                              \"See You Again\"[32]   \n",
       "4    5.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "5    6.                       \"Johny Johny Yes Papa\"[36]   \n",
       "6    7.                                \"Uptown Funk\"[37]   \n",
       "7    8.                              \"Gangnam Style\"[38]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[40]   \n",
       "9   10.                                      \"Sorry\"[41]   \n",
       "10  11.                                  \"Bath Song\"[42]   \n",
       "11  12.                                      \"Sugar\"[43]   \n",
       "12  13.                \"Phonics Song with Two Words\"[44]   \n",
       "13  14.                                       \"Roar\"[45]   \n",
       "14  15.                          \"Thinking Out Loud\"[46]   \n",
       "15  16.                             \"Counting Stars\"[47]   \n",
       "16  17.                               \"Shake It Off\"[48]   \n",
       "17  18.                             \"Dame Tu Cosita\"[49]   \n",
       "18  19.                                   \"Bailando\"[50]   \n",
       "19  20.                                    \"Lean On\"[51]   \n",
       "20  21.                                      \"Faded\"[52]   \n",
       "21  22.                                 \"Dark Horse\"[53]   \n",
       "22  23.                             \"Girls Like You\"[54]   \n",
       "23  24.                                 \"Let Her Go\"[55]   \n",
       "24  25.                                   \"Mi Gente\"[56]   \n",
       "25  26.                                      \"Hello\"[57]   \n",
       "26  27.                                \"Blank Space\"[58]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[59]   \n",
       "28  29.                                    \"Perfect\"[60]   \n",
       "29  30.                                   \"Chantaje\"[61]   \n",
       "\n",
       "                                               Artist Views        Upload Date  \n",
       "0                      Pinkfong Kids' Songs & Stories  7.39      June 17, 2016  \n",
       "1                   Luis Fonsi featuring Daddy Yankee  7.09   January 12, 2017  \n",
       "2                                          Ed Sheeran  5.10   January 30, 2017  \n",
       "3                  Wiz Khalifa featuring Charlie Puth  4.85      April 6, 2015  \n",
       "4                                          Get Movies  4.38   January 31, 2012  \n",
       "5                                         LooLoo Kids  4.37    October 8, 2016  \n",
       "6                    Mark Ronson featuring Bruno Mars  4.03  November 19, 2014  \n",
       "7                                                 Psy  3.88      July 15, 2012  \n",
       "8                                         Miroshka TV  3.66  February 27, 2018  \n",
       "9                                       Justin Bieber  3.37   October 22, 2015  \n",
       "10                         Cocomelon – Nursery Rhymes  3.34        May 2, 2018  \n",
       "11                                           Maroon 5  3.34   January 14, 2015  \n",
       "12                                          ChuChu TV  3.30      March 6, 2014  \n",
       "13                                         Katy Perry  3.22  September 5, 2013  \n",
       "14                                         Ed Sheeran  3.13    October 7, 2014  \n",
       "15                                        OneRepublic  3.13       May 31, 2013  \n",
       "16                                       Taylor Swift  2.99    August 18, 2014  \n",
       "17                    El Chombo featuring Cutty Ranks  2.94      April 5, 2018  \n",
       "18  Enrique Iglesias featuring Descemer Bueno and ...  2.94     April 11, 2014  \n",
       "19              Major Lazer and DJ Snake featuring MØ  2.93     March 22, 2015  \n",
       "20                                        Alan Walker  2.92   December 3, 2015  \n",
       "21                       Katy Perry featuring Juicy J  2.92  February 20, 2014  \n",
       "22                         Maroon 5 featuring Cardi B  2.91       May 31, 2018  \n",
       "23                                          Passenger  2.85      July 25, 2012  \n",
       "24                         J Balvin and Willy William  2.82      June 29, 2017  \n",
       "25                                              Adele  2.75   October 22, 2015  \n",
       "26                                       Taylor Swift  2.68  November 10, 2014  \n",
       "27                    Shakira featuring Freshlyground  2.66       June 4, 2010  \n",
       "28                                         Ed Sheeran  2.65   November 9, 2017  \n",
       "29                           Shakira featuring Maluma  2.60  November 18, 2016  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "\n",
    "#Loading Driver\n",
    "driver=webdriver.Edge(r\"C:\\Users\\PANKAJ\\Downloads\\msedgedriver.exe\")\n",
    "# Giving the name of website we have to  scrap\n",
    "url1 = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "#Getting Url \n",
    "driver.get(url1)\n",
    "# Details wich we want to scrap from the data\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "# lets scrap the data from the server\n",
    "rank=driver.find_elements_by_xpath(\"//tbody/tr/td[1]\")\n",
    "for r in rank[0:30]:\n",
    "    r_rank=r.text\n",
    "    Rank.append(r_rank)\n",
    "    Ra=pd.DataFrame(Rank)\n",
    "    Ra=Ra.rename({0: 'Rank'},axis=1)\n",
    "name=driver.find_elements_by_xpath(\"//tbody/tr/td[2]\")\n",
    "for n in name[0:30]:\n",
    "    n_rank=n.text\n",
    "    Name.append(n_rank)\n",
    "    N=pd.DataFrame(Name)\n",
    "    N=N.rename({0: 'Name'},axis=1)\n",
    "artist=driver.find_elements_by_xpath(\"//tbody/tr/td[3]\")\n",
    "for ar in artist[0:30]:\n",
    "    ar_rank=ar.text\n",
    "    Artist.append(ar_rank)\n",
    "    A=pd.DataFrame(Artist)\n",
    "    A=A.rename({0: 'Artist'},axis=1)\n",
    "view=driver.find_elements_by_xpath(\"//tbody/tr/td[4]\")\n",
    "for v in view[0:30]:\n",
    "    v_rank=v.text\n",
    "    Views.append(v_rank)\n",
    "    V=pd.DataFrame(Views)\n",
    "    V=V.rename({0: 'Views'},axis=1)\n",
    "date=driver.find_elements_by_xpath(\"//tbody/tr/td[5]\")\n",
    "for da in date[0:30]:\n",
    "    da_rank=da.text\n",
    "    Upload_date.append(da_rank)\n",
    "    UD=pd.DataFrame(Upload_date)\n",
    "    UD=UD.rename({0: 'Upload Date'},axis=1)\n",
    "\n",
    "# now lets add the whole data in  the table\n",
    "mwm=pd.concat([Ra,N,A,V,UD] , axis=1)\n",
    "mwm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Place Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>AUSTRALIA\\nv\\nINDIA</td>\n",
       "      <td>Adelaide Oval, Adelaide</td>\n",
       "      <td>17</td>\n",
       "      <td>DECEMBER</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>AUSTRALIA\\nv\\nINDIA</td>\n",
       "      <td>Melbourne Cricket Ground, Melbourne</td>\n",
       "      <td>26</td>\n",
       "      <td>DECEMBER</td>\n",
       "      <td>05:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>AUSTRALIA\\nv\\nINDIA</td>\n",
       "      <td>Sydney Cricket Ground, Sydney</td>\n",
       "      <td>07</td>\n",
       "      <td>JANUARY</td>\n",
       "      <td>05:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>AUSTRALIA\\nv\\nINDIA</td>\n",
       "      <td>Brisbane Cricket Ground, Brisbane</td>\n",
       "      <td>15</td>\n",
       "      <td>JANUARY</td>\n",
       "      <td>05:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>M. A. Chidambaram Stadium, Chennai</td>\n",
       "      <td>05</td>\n",
       "      <td>FEBRUARY</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>M. A. Chidambaram Stadium, Chennai</td>\n",
       "      <td>13</td>\n",
       "      <td>FEBRUARY</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>24</td>\n",
       "      <td>FEBRUARY</td>\n",
       "      <td>14:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>04</td>\n",
       "      <td>MARCH</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>12</td>\n",
       "      <td>MARCH</td>\n",
       "      <td>18:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>14</td>\n",
       "      <td>MARCH</td>\n",
       "      <td>18:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>16</td>\n",
       "      <td>MARCH</td>\n",
       "      <td>18:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>18</td>\n",
       "      <td>MARCH</td>\n",
       "      <td>18:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>Sardar Patel Stadium, Ahmedabad</td>\n",
       "      <td>20</td>\n",
       "      <td>MARCH</td>\n",
       "      <td>18:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>23</td>\n",
       "      <td>MARCH</td>\n",
       "      <td>14:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>26</td>\n",
       "      <td>MARCH</td>\n",
       "      <td>14:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA\\nv\\nENGLAND</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>28</td>\n",
       "      <td>MARCH</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>ENGLAND\\nv\\nINDIA</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>04</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>ENGLAND\\nv\\nINDIA</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>12</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>ENGLAND\\nv\\nINDIA</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>25</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>ENGLAND\\nv\\nINDIA</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>02</td>\n",
       "      <td>SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match Title          Series Name  \\\n",
       "0     1st Test  AUSTRALIA\\nv\\nINDIA   \n",
       "1     2nd Test  AUSTRALIA\\nv\\nINDIA   \n",
       "2     3rd Test  AUSTRALIA\\nv\\nINDIA   \n",
       "3     4th Test  AUSTRALIA\\nv\\nINDIA   \n",
       "4     1st Test    INDIA\\nv\\nENGLAND   \n",
       "5     2nd Test    INDIA\\nv\\nENGLAND   \n",
       "6     3rd Test    INDIA\\nv\\nENGLAND   \n",
       "7     4th Test    INDIA\\nv\\nENGLAND   \n",
       "8     1st Test    INDIA\\nv\\nENGLAND   \n",
       "9     2nd T20I    INDIA\\nv\\nENGLAND   \n",
       "10    3rd T20I    INDIA\\nv\\nENGLAND   \n",
       "11    4th T20I    INDIA\\nv\\nENGLAND   \n",
       "12    5th T20I    INDIA\\nv\\nENGLAND   \n",
       "13     1st ODI    INDIA\\nv\\nENGLAND   \n",
       "14     2nd ODI    INDIA\\nv\\nENGLAND   \n",
       "15     3rd ODI    INDIA\\nv\\nENGLAND   \n",
       "16    1st Test    ENGLAND\\nv\\nINDIA   \n",
       "17    2nd Test    ENGLAND\\nv\\nINDIA   \n",
       "18    3rd Test    ENGLAND\\nv\\nINDIA   \n",
       "19    4th Test    ENGLAND\\nv\\nINDIA   \n",
       "\n",
       "                                       Place Name Date      Month       Time  \n",
       "0                         Adelaide Oval, Adelaide   17   DECEMBER  09:30 IST  \n",
       "1             Melbourne Cricket Ground, Melbourne   26   DECEMBER  05:00 IST  \n",
       "2                   Sydney Cricket Ground, Sydney   07    JANUARY  05:00 IST  \n",
       "3               Brisbane Cricket Ground, Brisbane   15    JANUARY  05:30 IST  \n",
       "4              M. A. Chidambaram Stadium, Chennai   05   FEBRUARY  09:30 IST  \n",
       "5              M. A. Chidambaram Stadium, Chennai   13   FEBRUARY  09:30 IST  \n",
       "6                 Sardar Patel Stadium, Ahmedabad   24   FEBRUARY  14:00 IST  \n",
       "7                 Sardar Patel Stadium, Ahmedabad   04      MARCH  09:30 IST  \n",
       "8                 Sardar Patel Stadium, Ahmedabad   12      MARCH  18:00 IST  \n",
       "9                 Sardar Patel Stadium, Ahmedabad   14      MARCH  18:00 IST  \n",
       "10                Sardar Patel Stadium, Ahmedabad   16      MARCH  18:00 IST  \n",
       "11                Sardar Patel Stadium, Ahmedabad   18      MARCH  18:00 IST  \n",
       "12                Sardar Patel Stadium, Ahmedabad   20      MARCH  18:00 IST  \n",
       "13  Maharashtra Cricket Association Stadium, Pune   23      MARCH  14:30 IST  \n",
       "14  Maharashtra Cricket Association Stadium, Pune   26      MARCH  14:30 IST  \n",
       "15  Maharashtra Cricket Association Stadium, Pune   28      MARCH  09:30 IST  \n",
       "16                       Trent Bridge, Nottingham   04     AUGUST  15:30 IST  \n",
       "17                                 Lord's, London   12     AUGUST  15:30 IST  \n",
       "18                              Headingley, Leeds   25     AUGUST  15:30 IST  \n",
       "19                               The Oval, London   02  SEPTEMBER  15:30 IST  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Loading Driver\n",
    "driver=webdriver.Edge(r\"C:\\Users\\PANKAJ\\Downloads\\msedgedriver.exe\")\n",
    "# Giving the name of website we have to  scrap\n",
    "url1 = \"https://www.bcci.tv/international/fixtures\"\n",
    "#Getting Url \n",
    "driver.get(url1)\n",
    "# Details wich we want to scrap from the data\n",
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Month=[]\n",
    "Time=[]\n",
    "# lets scrap the data from the server\n",
    "match=driver.find_elements_by_xpath(\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "for m in match:\n",
    "    m_match=m.text\n",
    "    Match_title.append(m_match)\n",
    "    M=pd.DataFrame(Match_title)\n",
    "    M=M.rename({0: 'Match Title'},axis=1)\n",
    "series=driver.find_elements_by_xpath(\"//div[@class='fixture__teams']\")\n",
    "for s in series:\n",
    "    s_name=s.text\n",
    "    Series.append(s_name)\n",
    "    S=pd.DataFrame(Series)\n",
    "    S=S.rename({0: 'Series Name'},axis=1)\n",
    "place=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\")\n",
    "for p in place:\n",
    "    p_name=p.text\n",
    "    Place.append(p_name)\n",
    "    P=pd.DataFrame(Place)\n",
    "    P=P.rename({0: 'Place Name'},axis=1)\n",
    "date=driver.find_elements_by_xpath(\"//span[@class='fixture__date']\")\n",
    "for d in date:\n",
    "    dates=d.text\n",
    "    Date.append(dates)\n",
    "    D=pd.DataFrame(Date)\n",
    "    D=D.rename({0: 'Date'},axis=1)\n",
    "month=driver.find_elements_by_xpath(\"//span[@class='fixture__month']\")\n",
    "for m in month:\n",
    "    months=m.text\n",
    "    Month.append(months)\n",
    "    M1=pd.DataFrame(Month)\n",
    "    M1=M1.rename({0: 'Month'},axis=1)\n",
    "time=driver.find_elements_by_xpath(\"//span[@class='fixture__time']\")\n",
    "for t in time:\n",
    "    times=t.text\n",
    "    Time.append(times)\n",
    "    T=pd.DataFrame(Time)\n",
    "    T=T.rename({0: 'Time'},axis=1)\n",
    "# now lets add the whole data in  the table\n",
    "matches=pd.concat([M,S,P,D,M1,T] , axis=1)\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Scrape the details most watched tv series of all time from imdb.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movies Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010– )</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crime, Drama, Horror</td>\n",
       "      <td>45 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Movies Name    Year Span                     Genre Run Time\n",
       "0    Game of Thrones  (2011–2019)  Action, Adventure, Drama   57 min\n",
       "1    Stranger Things     (2016– )    Drama, Fantasy, Horror   51 min\n",
       "2   The Walking Dead     (2010– )   Drama, Horror, Thriller   44 min\n",
       "3     13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   60 min\n",
       "4            The 100  (2014–2020)    Drama, Mystery, Sci-Fi   43 min\n",
       "..               ...          ...                       ...      ...\n",
       "95               NaN          NaN            Drama, Fantasy   42 min\n",
       "96               NaN          NaN  Adventure, Comedy, Drama   50 min\n",
       "97               NaN          NaN     Crime, Drama, Mystery   42 min\n",
       "98               NaN          NaN      Crime, Drama, Horror   45 min\n",
       "99               NaN          NaN    Drama, Horror, Mystery  572 min\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "\n",
    "#Loading Driver\n",
    "driver=webdriver.Edge(r\"C:\\Users\\PANKAJ\\Downloads\\msedgedriver.exe\")\n",
    "# Giving the name of website we have to  scrap\n",
    "url1 = \"https://www.imdb.com/list/ls095964455/\"\n",
    "#Getting Url \n",
    "driver.get(url1)\n",
    "# Details wich we want to scrap from the data\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "# lets scrap the data from the server\n",
    "name=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a[@href]\")\n",
    "for n in name:\n",
    "    n_name=n.text\n",
    "    Name.append(n_name)\n",
    "    N=pd.DataFrame(Name)\n",
    "    N=N.rename({0: 'Movies Name'},axis=1)\n",
    "year=driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for y in year:\n",
    "    y_span=y.text\n",
    "    Year_span.append(y_span)\n",
    "    Y=pd.DataFrame(Year_span)\n",
    "    Y=Y.rename({0: 'Year Span'},axis=1)\n",
    "genre=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "for g in genre:\n",
    "    g_name=g.text\n",
    "    Genre.append(g_name)\n",
    "    G=pd.DataFrame(Genre)\n",
    "    G=G.rename({0: 'Genre'},axis=1)\n",
    "run=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "for r in run:\n",
    "    r_time=r.text\n",
    "    Run_time.append(r_time)\n",
    "    R=pd.DataFrame(Run_time)\n",
    "    R=R.rename({0: 'Run Time'},axis=1)\n",
    "rate=driver.find_elements_by_xpath(\"//span[@class='ipl-rating-star__rating']\")\n",
    "for r1 in rate:\n",
    "    r_rate=r1.text\n",
    "    Ratings.append(r_rate)\n",
    "    R1=pd.DataFrame(Ratings)\n",
    "    R1=R1.rename({0: 'Ratings'},axis=1)\n",
    "vote=driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']\")\n",
    "for v in vote:\n",
    "    v_total=v.text\n",
    "    Votes.append(v_total)\n",
    "    V=pd.DataFrame(Votes)\n",
    "    V=V.rename({0: 'Total Votes'},axis=1)\n",
    "# now lets add the whole data in  the table\n",
    "tm=pd.concat([N,Y,G,R] , axis=1)\n",
    "tm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the details of Data science recruiters from naukri.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Skills For Role</th>\n",
       "      <th>Job Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Talent Acquisition Executive</td>\n",
       "      <td>Recruitment Professional</td>\n",
       "      <td>XenonStack</td>\n",
       "      <td>Web Designing, html5, Angular.js, seo, hadoop,...</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jitendra Singh</td>\n",
       "      <td>Manager- Talent Acquisition</td>\n",
       "      <td>Compunnel Technology India Pvt. Ltd</td>\n",
       "      <td>Python, Data Science, .Net, Java, Big Data, Da...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Cochin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rakhi</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>Walkingtext Private Limited</td>\n",
       "      <td>Ites, Data Science, Cloud, Iot</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pooja Seth</td>\n",
       "      <td>IT Technical Recruiter</td>\n",
       "      <td>RAPS iTech</td>\n",
       "      <td>B.tech, Hr Mba, quality assurance engineering,...</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Java, Net, Angularjs, Hr, Infrastructure, Mana...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Software Architecture, Vp Engineering, Product...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Srikanth Bellup</td>\n",
       "      <td>Director</td>\n",
       "      <td>TeachR Robotics Pvt. Ltd</td>\n",
       "      <td>mechatronics, robotics, Home Automation, iot, ...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Data Science, Hadoop, Rpas, Devops, Python, Aw...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Signal Processing, Machine Learning, Neural Ne...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Web Technologies, Project Management, Software...</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Prateek Kumar</td>\n",
       "      <td>Head</td>\n",
       "      <td>Trisect</td>\n",
       "      <td>Java, Python, Angularjs, Software Testing, Mac...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Data Science, Machine Learning, Big Data Analy...</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Dat...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>C, C++, Artificial Intelligence, Python, Php, ...</td>\n",
       "      <td>Aligarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>Relationship Management, Retail Sales, Private...</td>\n",
       "      <td>Salt Lake City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Data Science, Software Engineering</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Data Science, Big Data Analytics, Digital Mark...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Data Science, Recruitment, Salary</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>B.Tech, Tableau, Statistics, R, Analytics, Tim...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Software Development, Business Intelligence, B...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Data Science, Node.js, Angularjs</td>\n",
       "      <td>MYSORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>Data Science, Media Marketing, Resource Planni...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Data Analysis, Learning, Data Science, Compute...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Java, Hadoop, R, Machine Learning, Spark, Flum...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Software Development, Core Java, Unit Testing,...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td>Machine Learning, Data Science, Product Manage...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Shailja Mishra</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Certybox Pvt.Ltd.</td>\n",
       "      <td>consulting, Education Counseling, Educational ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                    Talent Acquisition Executive   \n",
       "3                                    Anik Agrawal   \n",
       "4                        MARSIAN Technologies LLP   \n",
       "5                                    subhas patel   \n",
       "6                                  Jitendra Singh   \n",
       "7    Abhishek - Only Analytics Hiring - India and   \n",
       "8   Institute for Financial Management and Resear   \n",
       "9                                     Balu Ramesh   \n",
       "10                                  Asif Lucknowi   \n",
       "11                                InstaFinancials   \n",
       "12                                Kalpana Dumpala   \n",
       "13                                        Mubarak   \n",
       "14                                 Kushal Rastogi   \n",
       "15                                  Manisha Yadav   \n",
       "16                                   Kapil Devang   \n",
       "17                                    Riya Rajesh   \n",
       "18                                          Rakhi   \n",
       "19                             Mahesh Babu Channa   \n",
       "20                           Rashmi Bhattacharjee   \n",
       "21                                  Faizan Kareem   \n",
       "22                                 Rithika dadwal   \n",
       "23                                  Azahar Shaikh   \n",
       "24                                     Pooja Seth   \n",
       "25                             Sandhya Khandagale   \n",
       "26                                      Shaun Rao   \n",
       "27                                          Manas   \n",
       "28                                Srikanth Bellup   \n",
       "29                                          kumar   \n",
       "30                                   Sunil Vedula   \n",
       "31                                    Rajat Kumar   \n",
       "32                                      Jayanth N   \n",
       "33                                  Prateek Kumar   \n",
       "34                                       SREEDHAR   \n",
       "35                                    Amit Sharma   \n",
       "36                                          Kanan   \n",
       "37                           Shashikant Chaudhary   \n",
       "38                                           Brad   \n",
       "39                                   Rutuja Pawar   \n",
       "40                            Madhusudhan Sridhar   \n",
       "41                                    Ankit Sinha   \n",
       "42                                 Gaurav Chouhan   \n",
       "43                                   Rashi Kacker   \n",
       "44                                        Ashwini   \n",
       "45                                   Balaji Kolli   \n",
       "46                                 Rajani Nagaraj   \n",
       "47                                    ROHIT Kumar   \n",
       "48                                 Amir Chowdhury   \n",
       "49                                 Shailja Mishra   \n",
       "\n",
       "                      Designation  \\\n",
       "0                      HR Manager   \n",
       "1               Company Recruiter   \n",
       "2        Recruitment Professional   \n",
       "3               Company Recruiter   \n",
       "4                      Company HR   \n",
       "5                     Founder CEO   \n",
       "6     Manager- Talent Acquisition   \n",
       "7     Recruitment Lead Consultant   \n",
       "8               Programme Manager   \n",
       "9                HR Administrator   \n",
       "10                       Director   \n",
       "11                 Human Resource   \n",
       "12               Executive Hiring   \n",
       "13                     Company HR   \n",
       "14                     Company HR   \n",
       "15                   HR Executive   \n",
       "16                     HR Manager   \n",
       "17     Manager Talent Acquisition   \n",
       "18         Recruitment Consultant   \n",
       "19                   HR Team Lead   \n",
       "20                        HR Head   \n",
       "21                     HR MANAGER   \n",
       "22                   HR Recruiter   \n",
       "23              Company Recruiter   \n",
       "24         IT Technical Recruiter   \n",
       "25                   HR Recruiter   \n",
       "26        Manager Human Resources   \n",
       "27        Lead Talent acquisition   \n",
       "28                       Director   \n",
       "29                     Proprietor   \n",
       "30                            CEO   \n",
       "31                    Founder CEO   \n",
       "32                Project Manager   \n",
       "33                           Head   \n",
       "34         Recruitment Consultant   \n",
       "35                     Consultant   \n",
       "36   senior technology instructor   \n",
       "37       HR Recruiter/HR Excutive   \n",
       "38  Manager, Technical Recruiting   \n",
       "39            Technical Recruiter   \n",
       "40                Erp Implementer   \n",
       "41                 Head Analytics   \n",
       "42        Chief Technical Officer   \n",
       "43             Sr Product Manager   \n",
       "44       Director Global Delivery   \n",
       "45                     Co Founder   \n",
       "46                     HR Manager   \n",
       "47                      Architect   \n",
       "48               Managing Partner   \n",
       "49                     HR Manager   \n",
       "\n",
       "                                      Company Name  \\\n",
       "0                             Data Science Network   \n",
       "1                    Shore Infotech India Pvt. Ltd   \n",
       "2                                       XenonStack   \n",
       "3            Enerlytics Software Solutions Pvt Ltd   \n",
       "4                         MARSIAN Technologies LLP   \n",
       "5                                  LibraryXProject   \n",
       "6              Compunnel Technology India Pvt. Ltd   \n",
       "7       Apidel Technologies Division of Transpower   \n",
       "8                                             IFMR   \n",
       "9                      Techvantage Systems Pvt Ltd   \n",
       "10                      Weupskill- Live Wire India   \n",
       "11                CBL Data Science Private Limited   \n",
       "12                              Innominds Software   \n",
       "13                                        MoneyTap   \n",
       "14              QuantMagnum Technologies Pvt. Ltd.   \n",
       "15                                        Easi Tax   \n",
       "16                                  BISP Solutions   \n",
       "17                     Novelworx Digital Solutions   \n",
       "18                     Walkingtext Private Limited   \n",
       "19                               SocialPrachar.com   \n",
       "20         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...   \n",
       "21                   FirstTech Consaltants Pvt.Ltd   \n",
       "22                                Affine Analytics   \n",
       "23                 NEAL ANALYTICS SERVICES PVT LTD   \n",
       "24                                      RAPS iTech   \n",
       "25                 Compumatrice Multimedia Pvt Ltd   \n",
       "26                              Exela Technologies   \n",
       "27      Autumn Leaf Consulting Services Private...   \n",
       "28                        TeachR Robotics Pvt. Ltd   \n",
       "29                                         trainin   \n",
       "30                            Nanoprecise Sci Corp   \n",
       "31                  R.S Consultancy &amp; Services   \n",
       "32        Dollarbird Information Services Pvt, Ltd   \n",
       "33                                         Trisect   \n",
       "34     JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "35                                 ASCO consulting   \n",
       "36                                         NY INST   \n",
       "37  3D India Staffing Research &amp; Consulting...   \n",
       "38                                     O.C. Tanner   \n",
       "39                                   Demand Matrix   \n",
       "40                             MADHUSUDHAN SRIDHAR   \n",
       "41                                  Suntech Global   \n",
       "42                        Strategic Consulting Lab   \n",
       "43                            Impel Labs Pvt. Ltd.   \n",
       "44                                    MRP Advisers   \n",
       "45                   Saras Solutions India Pvt Ltd   \n",
       "46                                     WildJasmine   \n",
       "47                             LNT Private Limited   \n",
       "48                                     Granular.ai   \n",
       "49                               Certybox Pvt.Ltd.   \n",
       "\n",
       "                                      Skills For Role  \\\n",
       "0   Classic ASP Developer, Internet Marketing Prof...   \n",
       "1   .Net, Java, Data Science, Linux Administration...   \n",
       "2   Web Designing, html5, Angular.js, seo, hadoop,...   \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...   \n",
       "4   Data Science, Artificial Intelligence, Machine...   \n",
       "5   Hadoop, Spark, Digital Strategy, Data Architec...   \n",
       "6   Python, Data Science, .Net, Java, Big Data, Da...   \n",
       "7   Analytics, Business Intelligence, Business Ana...   \n",
       "8                                        Data Science   \n",
       "9   Machine Learning, algorithms, Go Getter, Compu...   \n",
       "10  Technical Training, Software Development, Pres...   \n",
       "11  Software Development, It Sales, Account Manage...   \n",
       "12  Qa, Ui/ux, Java Developer, Java Architect, C++...   \n",
       "13  Business Intelligence, Data Warehousing, Data ...   \n",
       "14  Office Administration, Hr Administration, tele...   \n",
       "15  Telecalling, Client Interaction, Marketing, Re...   \n",
       "16     Big Data, Hadoop, Data Analytics, Data Science   \n",
       "17                                       Data Science   \n",
       "18                     Ites, Data Science, Cloud, Iot   \n",
       "19  Social Media, digital media maketing, seo, smm...   \n",
       "20  Corporate Sales, Software Development, Softwar...   \n",
       "21  Data Analytics, Data Science, Machine Learning...   \n",
       "22  Data Science, Machine Learning, Python, R, Dee...   \n",
       "23  Data Science, Artificial Intelligence, Machine...   \n",
       "24  B.tech, Hr Mba, quality assurance engineering,...   \n",
       "25  Big Data, Data Science, Artificial Intelligenc...   \n",
       "26  Java, Net, Angularjs, Hr, Infrastructure, Mana...   \n",
       "27  Software Architecture, Vp Engineering, Product...   \n",
       "28  mechatronics, robotics, Home Automation, iot, ...   \n",
       "29  Data Science, Hadoop, Rpas, Devops, Python, Aw...   \n",
       "30  Signal Processing, Machine Learning, Neural Ne...   \n",
       "31  Web Technologies, Project Management, Software...   \n",
       "32  Data Analytics, Managed Services, Team Leading...   \n",
       "33  Java, Python, Angularjs, Software Testing, Mac...   \n",
       "34  Data Science, Machine Learning, Big Data Analy...   \n",
       "35  Machine Learning, Artificial Intelligence, Dat...   \n",
       "36  C, C++, Artificial Intelligence, Python, Php, ...   \n",
       "37  Relationship Management, Retail Sales, Private...   \n",
       "38                 Data Science, Software Engineering   \n",
       "39  Data Science, Big Data Analytics, Digital Mark...   \n",
       "40                  Data Science, Recruitment, Salary   \n",
       "41  B.Tech, Tableau, Statistics, R, Analytics, Tim...   \n",
       "42  Software Development, Business Intelligence, B...   \n",
       "43                   Data Science, Node.js, Angularjs   \n",
       "44  Data Science, Media Marketing, Resource Planni...   \n",
       "45  Data Analysis, Learning, Data Science, Compute...   \n",
       "46  Java, Hadoop, R, Machine Learning, Spark, Flum...   \n",
       "47  Software Development, Core Java, Unit Testing,...   \n",
       "48  Machine Learning, Data Science, Product Manage...   \n",
       "49  consulting, Education Counseling, Educational ...   \n",
       "\n",
       "                Job Location  \n",
       "0                      Delhi  \n",
       "1   Hyderabad / Secunderabad  \n",
       "2                 Chandigarh  \n",
       "3                  Ahmedabad  \n",
       "4                       Pune  \n",
       "5              UK - (london)  \n",
       "6                      Delhi  \n",
       "7          Vadodara / Baroda  \n",
       "8                    Chennai  \n",
       "9                 Trivandrum  \n",
       "10                    Indore  \n",
       "11     Bengaluru / Bangalore  \n",
       "12  Hyderabad / Secunderabad  \n",
       "13     Bengaluru / Bangalore  \n",
       "14                    Mumbai  \n",
       "15               Navi Mumbai  \n",
       "16                    Bhopal  \n",
       "17                    Cochin  \n",
       "18     Bengaluru / Bangalore  \n",
       "19  Hyderabad / Secunderabad  \n",
       "20                     Delhi  \n",
       "21  Hyderabad / Secunderabad  \n",
       "22                      Pune  \n",
       "23                      Pune  \n",
       "24                Chandigarh  \n",
       "25                      Pune  \n",
       "26                      Pune  \n",
       "27     Bengaluru / Bangalore  \n",
       "28  Hyderabad / Secunderabad  \n",
       "29     Bengaluru / Bangalore  \n",
       "30                     Delhi  \n",
       "31           Mysoru / Mysore  \n",
       "32                     Noida  \n",
       "33  Hyderabad / Secunderabad  \n",
       "34                 New Delhi  \n",
       "35                   Chennai  \n",
       "36                   Aligarh  \n",
       "37            Salt Lake City  \n",
       "38                      Pune  \n",
       "39     Bengaluru / Bangalore  \n",
       "40                    Mumbai  \n",
       "41                    Indore  \n",
       "42     Bengaluru / Bangalore  \n",
       "43                    MYSORE  \n",
       "44  Hyderabad / Secunderabad  \n",
       "45     Bengaluru / Bangalore  \n",
       "46                    Mumbai  \n",
       "47                     Noida  \n",
       "48                       NaN  \n",
       "49                       NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "\n",
    "#Loading Driver\n",
    "driver=webdriver.Edge(r\"C:\\Users\\PANKAJ\\Downloads\\msedgedriver.exe\")\n",
    "# Giving the name of website we have to  scrap\n",
    "url1 = \"https://www.naukri.com/data-science-recruiters\"\n",
    "#Getting Url \n",
    "driver.get(url1)\n",
    "# Details wich we want to scrap from the data\n",
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills=[]\n",
    "Location=[]\n",
    "# lets scrap the data from the server\n",
    "name=driver.find_elements_by_xpath(\"//span[@class='fl ellipsis']\")\n",
    "for n in name:\n",
    "    n_name=n.text\n",
    "    Name.append(n_name)\n",
    "    N=pd.DataFrame(Name)\n",
    "    N=N.rename({0: 'Name'},axis=1)\n",
    "profile=driver.find_elements_by_xpath(\"//span[@class='ellipsis clr']\")\n",
    "for d in profile:\n",
    "    d_name=d.text\n",
    "    Designation.append(d_name)\n",
    "    D=pd.DataFrame(Designation)\n",
    "    D=D.rename({0: 'Designation'},axis=1)\n",
    "company=driver.find_elements_by_xpath(\"//a[@class='ellipsis']\")\n",
    "for c in company:\n",
    "    c_name=c.text\n",
    "    Company.append(c_name)\n",
    "    C1=Company[1: :2]\n",
    "    C2=pd.DataFrame(C1)\n",
    "    C2=C2.rename({0: 'Company Name'},axis=1)\n",
    "skill=driver.find_elements_by_xpath(\"//div[@class='hireSec highlightable']\")\n",
    "for s in skill:\n",
    "    s_required=s.text\n",
    "    Skills.append(s_required)\n",
    "    S=pd.DataFrame(Skills)\n",
    "    S=S.rename({0: 'Skills For Role'},axis=1)\n",
    "location=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "for l in location:\n",
    "    l_name=l.text\n",
    "    Location.append(l_name)\n",
    "    L=pd.DataFrame(Location)\n",
    "    L=L.rename({0: 'Job Location'},axis=1)\n",
    "# now lets add the whole data in  the table\n",
    "DSR=pd.concat([N,D,C2,S,L] , axis=1)\n",
    "DSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the details of trending repositories on Github.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Language_used</th>\n",
       "      <th>Contributors Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WerWolv / ImHex</td>\n",
       "      <td>A Hex Editor for Reverse Engineers, Programmer...</td>\n",
       "      <td>C++</td>\n",
       "      <td>2,834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nickmccullum / algorithmic-trading-python</td>\n",
       "      <td>The repository for freeCodeCamp's YouTube cour...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alacritty / alacritty</td>\n",
       "      <td>A cross-platform, GPU-accelerated terminal emu...</td>\n",
       "      <td>Rust</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bytefury / crater</td>\n",
       "      <td>Free &amp; Open Source Invoice App for Freelancers...</td>\n",
       "      <td>PHP</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jwasham / coding-interview-university</td>\n",
       "      <td>A complete computer science study plan to beco...</td>\n",
       "      <td>C</td>\n",
       "      <td>28,196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acidanthera / OpenCorePkg</td>\n",
       "      <td>OpenCore bootloader</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>1,432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>github / docs</td>\n",
       "      <td>The open-source repo for docs.github.com</td>\n",
       "      <td>Python</td>\n",
       "      <td>3,226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3b1b / manim</td>\n",
       "      <td>Animation engine for explanatory math videos</td>\n",
       "      <td>Go</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rclone / rclone</td>\n",
       "      <td>\"rsync for cloud storage\" - Google Drive, Amaz...</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>144,619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rapid7 / metasploit-framework</td>\n",
       "      <td>Metasploit Framework</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>40,802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CSSEGISandData / COVID-19</td>\n",
       "      <td>Novel Coronavirus (COVID-19) Cases, provided b...</td>\n",
       "      <td>Python</td>\n",
       "      <td>5,571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ottomated / CrewLink-server</td>\n",
       "      <td>Voice Relay server for CrewLink.</td>\n",
       "      <td>C#</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>public-apis / public-apis</td>\n",
       "      <td>A collective list of free APIs for use in soft...</td>\n",
       "      <td>Python</td>\n",
       "      <td>1,716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SebLague / Digital-Logic-Sim</td>\n",
       "      <td>A list of useful payloads and bypass for Web A...</td>\n",
       "      <td>Go</td>\n",
       "      <td>5,592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>swisskyrepo / PayloadsAllTheThings</td>\n",
       "      <td>🗂 The perfect Front-End Checklist for modern w...</td>\n",
       "      <td>Python</td>\n",
       "      <td>28,654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>thedaviddias / Front-End-Checklist</td>\n",
       "      <td>Docker-compatible CLI for containerd</td>\n",
       "      <td>Python</td>\n",
       "      <td>3,659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AkihiroSuda / nerdctl</td>\n",
       "      <td>RESTler is the first stateful REST API fuzzing...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>24,664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>microsoft / restler-fuzzer</td>\n",
       "      <td>🏡 Open source home automation that puts local ...</td>\n",
       "      <td>C++</td>\n",
       "      <td>2,129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>home-assistant / core</td>\n",
       "      <td>Free, open, Among Us Proximity Chat</td>\n",
       "      <td>Vim script</td>\n",
       "      <td>22,382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ottomated / CrewLink</td>\n",
       "      <td>Animated sprite editor &amp; pixel art tool (Windo...</td>\n",
       "      <td>Python</td>\n",
       "      <td>10,725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aseprite / aseprite</td>\n",
       "      <td>Vim-fork focused on extensibility and usability</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>24,991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>neovim / neovim</td>\n",
       "      <td>Deep learning models for guitar amp/pedal emul...</td>\n",
       "      <td>Go</td>\n",
       "      <td>15,993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GuitarML / GuitarLSTM</td>\n",
       "      <td>A powerful JavaScript library for interacting ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>discordjs / discord.js</td>\n",
       "      <td>A modern tool for the Windows kernel explorati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Repository title  \\\n",
       "0                             WerWolv / ImHex   \n",
       "1   nickmccullum / algorithmic-trading-python   \n",
       "2                       alacritty / alacritty   \n",
       "3                           bytefury / crater   \n",
       "4       jwasham / coding-interview-university   \n",
       "5                   acidanthera / OpenCorePkg   \n",
       "6                               github / docs   \n",
       "7                                3b1b / manim   \n",
       "8                             rclone / rclone   \n",
       "9               rapid7 / metasploit-framework   \n",
       "10                  CSSEGISandData / COVID-19   \n",
       "11                ottomated / CrewLink-server   \n",
       "12                  public-apis / public-apis   \n",
       "13               SebLague / Digital-Logic-Sim   \n",
       "14         swisskyrepo / PayloadsAllTheThings   \n",
       "15         thedaviddias / Front-End-Checklist   \n",
       "16                      AkihiroSuda / nerdctl   \n",
       "17                 microsoft / restler-fuzzer   \n",
       "18                      home-assistant / core   \n",
       "19                       ottomated / CrewLink   \n",
       "20                        aseprite / aseprite   \n",
       "21                            neovim / neovim   \n",
       "22                      GuitarML / GuitarLSTM   \n",
       "23                     discordjs / discord.js   \n",
       "\n",
       "                               Repository_description     Language_used  \\\n",
       "0   A Hex Editor for Reverse Engineers, Programmer...               C++   \n",
       "1   The repository for freeCodeCamp's YouTube cour...  Jupyter Notebook   \n",
       "2   A cross-platform, GPU-accelerated terminal emu...              Rust   \n",
       "3   Free & Open Source Invoice App for Freelancers...               PHP   \n",
       "4   A complete computer science study plan to beco...                 C   \n",
       "5                                 OpenCore bootloader        JavaScript   \n",
       "6            The open-source repo for docs.github.com            Python   \n",
       "7        Animation engine for explanatory math videos                Go   \n",
       "8   \"rsync for cloud storage\" - Google Drive, Amaz...              Ruby   \n",
       "9                                Metasploit Framework        TypeScript   \n",
       "10  Novel Coronavirus (COVID-19) Cases, provided b...            Python   \n",
       "11                   Voice Relay server for CrewLink.                C#   \n",
       "12  A collective list of free APIs for use in soft...            Python   \n",
       "13  A list of useful payloads and bypass for Web A...                Go   \n",
       "14  🗂 The perfect Front-End Checklist for modern w...            Python   \n",
       "15               Docker-compatible CLI for containerd            Python   \n",
       "16  RESTler is the first stateful REST API fuzzing...        TypeScript   \n",
       "17  🏡 Open source home automation that puts local ...               C++   \n",
       "18                Free, open, Among Us Proximity Chat        Vim script   \n",
       "19  Animated sprite editor & pixel art tool (Windo...            Python   \n",
       "20    Vim-fork focused on extensibility and usability        JavaScript   \n",
       "21  Deep learning models for guitar amp/pedal emul...                Go   \n",
       "22  A powerful JavaScript library for interacting ...               NaN   \n",
       "23  A modern tool for the Windows kernel explorati...               NaN   \n",
       "\n",
       "   Contributors Count  \n",
       "0               2,834  \n",
       "1                  83  \n",
       "2                 118  \n",
       "3                  49  \n",
       "4              28,196  \n",
       "5               1,432  \n",
       "6               3,226  \n",
       "7                 619  \n",
       "8             144,619  \n",
       "9              40,802  \n",
       "10              5,571  \n",
       "11                963  \n",
       "12              1,716  \n",
       "13              5,592  \n",
       "14             28,654  \n",
       "15              3,659  \n",
       "16             24,664  \n",
       "17              2,129  \n",
       "18             22,382  \n",
       "19             10,725  \n",
       "20             24,991  \n",
       "21             15,993  \n",
       "22                145  \n",
       "23                 68  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "#Loading Driver\n",
    "driver=webdriver.Edge(r\"C:\\Users\\PANKAJ\\Downloads\\msedgedriver.exe\")\n",
    "# Giving the name of website we have to  scrap\n",
    "url1 = \"https://github.com/trending\"\n",
    "#Getting Url \n",
    "driver.get(url1)\n",
    "# Details wich we want to scrap from the data\n",
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "# lets scrap the data from the server\n",
    "rt=driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']\")\n",
    "for r in rt:\n",
    "    r_title=r.text\n",
    "    Repository_title.append(r_title)\n",
    "    R=pd.DataFrame(Repository_title)\n",
    "    R=R.rename({0: 'Repository title'},axis=1)\n",
    "rd=driver.find_elements_by_xpath(\"//p[@class='col-9 text-gray my-1 pr-4']\")\n",
    "for r1 in rd:\n",
    "    r1_des=r1.text\n",
    "    Repository_description.append(r1_des)\n",
    "    R1=pd.DataFrame(Repository_description)\n",
    "    R1=R1.rename({0: 'Repository_description'},axis=1)\n",
    "ll=driver.find_elements_by_xpath(\"//span[@class='d-inline-block ml-0 mr-3']\")\n",
    "for l in ll:\n",
    "    l_name=l.text\n",
    "    Language_used.append(l_name)\n",
    "    L=pd.DataFrame(Language_used)\n",
    "    L=L.rename({0: 'Language_used'},axis=1)\n",
    "cc=driver.find_elements_by_xpath(\"//a[@class='muted-link d-inline-block mr-3']\") \n",
    "for c in cc:\n",
    "    c_count=c.text\n",
    "    Contributors_count.append(c_count)\n",
    "    C=pd.DataFrame(Contributors_count)\n",
    "    C=C.rename({0: 'Contributors Count'},axis=1)  \n",
    "# now lets add the whole data in  the table\n",
    "TR=pd.concat([R,R1,L,C] , axis=1)\n",
    "TR[0:24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the details of top 100 songs on billiboard.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last_Week_Rank</th>\n",
       "      <th>Peak_Rank</th>\n",
       "      <th>Weeks_On_Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Life Goes On</td>\n",
       "      <td>BTS</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mood</td>\n",
       "      <td>24kGoldn Featuring iann dior</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dynamite</td>\n",
       "      <td>BTS</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positions</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I Hope</td>\n",
       "      <td>Gabby Barrett Featuring Charlie Puth</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Popstar</td>\n",
       "      <td>DJ Khaled Featuring Drake</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Bichota</td>\n",
       "      <td>Karol G</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Happy Does</td>\n",
       "      <td>Kenny Chesney</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Cover Me Up</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>So Done</td>\n",
       "      <td>The Kid LAROI</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Song                                Artist Last_Week_Rank  \\\n",
       "0   Life Goes On                                   BTS              -   \n",
       "1           Mood          24kGoldn Featuring iann dior              1   \n",
       "2       Dynamite                                   BTS             14   \n",
       "3      Positions                         Ariana Grande              3   \n",
       "4         I Hope  Gabby Barrett Featuring Charlie Puth              3   \n",
       "..           ...                                   ...            ...   \n",
       "95       Popstar             DJ Khaled Featuring Drake              3   \n",
       "96       Bichota                               Karol G              -   \n",
       "97    Happy Does                         Kenny Chesney             85   \n",
       "98   Cover Me Up                         Morgan Wallen              -   \n",
       "99       So Done                         The Kid LAROI             59   \n",
       "\n",
       "   Peak_Rank Weeks_On_Board  \n",
       "0          1              1  \n",
       "1          1             16  \n",
       "2          1             14  \n",
       "3          1              5  \n",
       "4          3             48  \n",
       "..       ...            ...  \n",
       "95         3             19  \n",
       "96        97              1  \n",
       "97        85              6  \n",
       "98        99              1  \n",
       "99        59              5  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the library in juypter notebook\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "# importing web driver from its location\n",
    "driver=webdriver.Edge(r\"C:\\Users\\PANKAJ\\Downloads\\msedgedriver.exe\")\n",
    "Url = 'https://www.billboard.com/charts/hot-100'\n",
    "driver.get(Url)\n",
    "# finding the state wise attached detail\n",
    "Song=[]\n",
    "Artist=[]\n",
    "Last_Week_Rank=[]\n",
    "Peak_Rank=[]\n",
    "Weeks_On_Board=[]\n",
    "# lets scrap the data from the server\n",
    "song=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "for so in song:\n",
    "    so_song=so.text\n",
    "    Song.append(so_song)\n",
    "    S=pd.DataFrame(Song)\n",
    "    S=S.rename({0: 'Song'},axis=1)\n",
    "artist=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "for ar in artist:\n",
    "    ar_song=ar.text\n",
    "    Artist.append(ar_song)\n",
    "    A=pd.DataFrame(Artist)\n",
    "    A=A.rename({0: 'Artist'},axis=1)\n",
    "lwr=driver.find_elements_by_xpath(\"//div[@class='chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[2]\")\n",
    "for lw in lwr:\n",
    "    lw_song=lw.text\n",
    "    Last_Week_Rank.append(lw_song)\n",
    "    L=pd.DataFrame(Last_Week_Rank)\n",
    "    L=L.rename({0: 'Last_Week_Rank'},axis=1)\n",
    "pr=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for p in pr:\n",
    "    pr_song=p.text\n",
    "    Peak_Rank.append(pr_song)\n",
    "    P=pd.DataFrame(Peak_Rank)\n",
    "    P=P.rename({0: 'Peak_Rank'},axis=1)   \n",
    "wob=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for w in wob:\n",
    "    w_song=w.text\n",
    "    Weeks_On_Board.append(w_song)\n",
    "    W=pd.DataFrame(Weeks_On_Board)\n",
    "    W=W.rename({0: 'Weeks_On_Board'},axis=1)   \n",
    "#Lets create a table of top 100 movies data\n",
    "movies=pd.concat([S,A,L,P,W] , axis=1)\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the details of State-wise GDP of India from statisticstime.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>GSDP(17-18)</th>\n",
       "      <th>Share(2017)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,411,600</td>\n",
       "      <td>14.11%</td>\n",
       "      <td>374.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,542,432</td>\n",
       "      <td>1,376,324</td>\n",
       "      <td>8.05%</td>\n",
       "      <td>213.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,314,680</td>\n",
       "      <td>7.69%</td>\n",
       "      <td>203.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>929,124</td>\n",
       "      <td>835,558</td>\n",
       "      <td>4.89%</td>\n",
       "      <td>129.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>865,688</td>\n",
       "      <td>753,811</td>\n",
       "      <td>4.41%</td>\n",
       "      <td>116.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>700,532</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>108.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>707,126</td>\n",
       "      <td>626,054</td>\n",
       "      <td>3.66%</td>\n",
       "      <td>97.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>521,861</td>\n",
       "      <td>479,141</td>\n",
       "      <td>2.80%</td>\n",
       "      <td>74.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>288,494</td>\n",
       "      <td>1.69%</td>\n",
       "      <td>44.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>307,581</td>\n",
       "      <td>276,243</td>\n",
       "      <td>1.62%</td>\n",
       "      <td>42.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,181</td>\n",
       "      <td>140,613</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>21.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>77,172</td>\n",
       "      <td>70,493</td>\n",
       "      <td>0.41%</td>\n",
       "      <td>10.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>38,806</td>\n",
       "      <td>0.23%</td>\n",
       "      <td>6.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>-</td>\n",
       "      <td>30,790</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>4.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>23,968</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>3.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>22,045</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>7,871</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>1.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,139,378</td>\n",
       "      <td>14.14%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,398,579</td>\n",
       "      <td>1,231,090</td>\n",
       "      <td>8.14%</td>\n",
       "      <td>1,026,675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,151,150</td>\n",
       "      <td>7.61%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>833,777</td>\n",
       "      <td>749,462</td>\n",
       "      <td>4.95%</td>\n",
       "      <td>602,078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>786,991</td>\n",
       "      <td>684,500</td>\n",
       "      <td>4.52%</td>\n",
       "      <td>555,084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>634,675</td>\n",
       "      <td>4.20%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>639,273</td>\n",
       "      <td>565,509</td>\n",
       "      <td>3.74%</td>\n",
       "      <td>474,451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>473,379</td>\n",
       "      <td>431,127</td>\n",
       "      <td>2.85%</td>\n",
       "      <td>355,872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>279,441</td>\n",
       "      <td>254,925</td>\n",
       "      <td>1.69%</td>\n",
       "      <td>206,015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>251,588</td>\n",
       "      <td>1.66%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>131,638</td>\n",
       "      <td>121,491</td>\n",
       "      <td>0.80%</td>\n",
       "      <td>100,558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>71,884</td>\n",
       "      <td>64,420</td>\n",
       "      <td>0.43%</td>\n",
       "      <td>56,634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>34,578</td>\n",
       "      <td>0.23%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>-</td>\n",
       "      <td>27,679</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>29</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>21,532</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>20,171</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>7,041</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19) GSDP(17-18) Share(2017)  \\\n",
       "0     1                Maharashtra           -   2,411,600      14.11%   \n",
       "1     3              Uttar Pradesh   1,542,432   1,376,324       8.05%   \n",
       "2     5                    Gujarat           -   1,314,680       7.69%   \n",
       "3     7                  Rajasthan     929,124     835,558       4.89%   \n",
       "4     9                  Telangana     865,688     753,811       4.41%   \n",
       "5    11                     Kerala           -     700,532       4.10%   \n",
       "6    13                    Haryana     707,126     626,054       3.66%   \n",
       "7    15                     Punjab     521,861     479,141       2.80%   \n",
       "8    17                      Assam           -     288,494       1.69%   \n",
       "9    19                  Jharkhand     307,581     276,243       1.62%   \n",
       "10   21           Himachal Pradesh     153,181     140,613       0.82%   \n",
       "11   23                        Goa      77,172      70,493       0.41%   \n",
       "12   25                 Chandigarh           -      38,806       0.23%   \n",
       "13   27                  Meghalaya           -      30,790       0.18%   \n",
       "14   29                    Manipur           -      23,968       0.14%   \n",
       "15   31          Arunachal Pradesh           -      22,045       0.13%   \n",
       "16   33  Andaman & Nicobar Islands           -       7,871       0.05%   \n",
       "17    1                Maharashtra           -   2,139,378      14.14%   \n",
       "18    3                  Karnataka   1,398,579   1,231,090       8.14%   \n",
       "19    5                    Gujarat           -   1,151,150       7.61%   \n",
       "20    7                  Rajasthan     833,777     749,462       4.95%   \n",
       "21    9                  Telangana     786,991     684,500       4.52%   \n",
       "22   11                     Kerala           -     634,675       4.20%   \n",
       "23   13                    Haryana     639,273     565,509       3.74%   \n",
       "24   15                     Punjab     473,379     431,127       2.85%   \n",
       "25   17               Chhattisgarh     279,441     254,925       1.69%   \n",
       "26   19                      Assam           -     251,588       1.66%   \n",
       "27   21           Himachal Pradesh     131,638     121,491       0.80%   \n",
       "28   23                        Goa      71,884      64,420       0.43%   \n",
       "29   25                 Chandigarh           -      34,578       0.23%   \n",
       "30   27                  Meghalaya           -      27,679       0.18%   \n",
       "31   29                   Nagaland           -      21,532       0.14%   \n",
       "32   31          Arunachal Pradesh           -      20,171       0.13%   \n",
       "33   33  Andaman & Nicobar Islands           -       7,041       0.05%   \n",
       "\n",
       "   GDP($ billion)  \n",
       "0         374.196  \n",
       "1         213.558  \n",
       "2         203.993  \n",
       "3         129.650  \n",
       "4         116.965  \n",
       "5         108.698  \n",
       "6          97.142  \n",
       "7          74.346  \n",
       "8          44.764  \n",
       "9          42.863  \n",
       "10         21.818  \n",
       "11         10.938  \n",
       "12          6.021  \n",
       "13          4.778  \n",
       "14          3.719  \n",
       "15          3.421  \n",
       "16          1.221  \n",
       "17              -  \n",
       "18      1,026,675  \n",
       "19              -  \n",
       "20        602,078  \n",
       "21        555,084  \n",
       "22              -  \n",
       "23        474,451  \n",
       "24        355,872  \n",
       "25        206,015  \n",
       "26              -  \n",
       "27        100,558  \n",
       "28         56,634  \n",
       "29              -  \n",
       "30              -  \n",
       "31              -  \n",
       "32              -  \n",
       "33              -  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the library in juypter notebook\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "# importing web driver from its location\n",
    "driver=webdriver.Edge(r\"C:\\Users\\PANKAJ\\Downloads\\msedgedriver.exe\")\n",
    "Url = 'http://statisticstimes.com/economy/gdp-of-indian-states.php'\n",
    "driver.get(Url)\n",
    "# finding the state wise attached detail\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP18=[]\n",
    "GSDP17=[]\n",
    "Share17=[]\n",
    "GDP=[]\n",
    "# lets scrap the data from the server\n",
    "rank=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[1]\")\n",
    "for r in rank:\n",
    "    r_rank=r.text\n",
    "    Rank.append(r_rank)\n",
    "    R=pd.DataFrame(Rank)\n",
    "    R=R.rename({0: 'Rank'},axis=1)\n",
    "state=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[2]\")\n",
    "for s in state:\n",
    "    s_state=s.text\n",
    "    State.append(s_state) \n",
    "    S=pd.DataFrame(State)\n",
    "    S=S.rename({0: 'State'},axis=1)\n",
    "gsdp=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[3]\")\n",
    "for g in gsdp:\n",
    "    g_gsdp=g.text\n",
    "    GSDP18.append(g_gsdp)\n",
    "    G=pd.DataFrame(GSDP18)\n",
    "    G=G.rename({0: 'GSDP(18-19)'},axis=1)\n",
    "gsdp1=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[4]\")\n",
    "for g1 in gsdp1:\n",
    "    g_gsdp1=g1.text\n",
    "    GSDP17.append(g_gsdp1)\n",
    "    G1=pd.DataFrame(GSDP17)\n",
    "    G1=G1.rename({0: 'GSDP(17-18)'},axis=1)\n",
    "share=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[5]\")\n",
    "for s1 in share:\n",
    "    s_share=s1.text\n",
    "    Share17.append(s_share)\n",
    "    S1=pd.DataFrame(Share17)\n",
    "    S1=S1.rename({0: 'Share(2017)'},axis=1)\n",
    "gdp=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[6]\")\n",
    "for gb in gdp:\n",
    "    gb_gdp=gb.text\n",
    "    GDP.append(gb_gdp)\n",
    "    GB=pd.DataFrame(GDP)\n",
    "    GB=GB.rename({0: 'GDP($ billion)'},axis=1)\n",
    "# Now Lets create the State wise GPD Table \n",
    "df=pd.concat([R,S,G,G1,S1,GB] , axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the details of Highest selling novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Loading Driver\n",
    "driver=webdriver.Edge(r\"C:\\Users\\PANKAJ\\Downloads\\msedgedriver.exe\")\n",
    "\n",
    "# Giving the name of website we have to  scrap\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "\n",
    "#Getting Url \n",
    "driver.get(url)\n",
    "\n",
    "book_name = []\n",
    "author_name  = []\n",
    "volumes_sold  = []\n",
    "publisher  = []\n",
    "genre  = []\n",
    "# lets scrap the data from the server\n",
    "Task1 = driver.find_elements_by_xpath(\"//tbody/tr/td[2]\")\n",
    "\n",
    "for qt in Task1:\n",
    "    qx = qt.text\n",
    "    book_name.append(qx)\n",
    "\n",
    "book_name1 =pd.DataFrame(book_name)\n",
    "book_name2= book_name1.rename(columns = { 0: 'Book Name'})\n",
    "\n",
    "Task2 = driver.find_elements_by_xpath(\"//tbody/tr/td[3]\")\n",
    "\n",
    "for qm in Task2:\n",
    "    ql = qm.text\n",
    "    author_name.append(ql)\n",
    "\n",
    "author_name1 = pd.DataFrame(author_name)\n",
    "author_name2 = author_name1.rename(columns= {0:'Author Name'})\n",
    "\n",
    "Task3 = driver.find_elements_by_xpath(\"//tbody/tr/td[4]\")\n",
    "\n",
    "for wp in Task3:\n",
    "    wm = wp.text\n",
    "    volumes_sold.append(wm)\n",
    "volumes_sold[0:5]\n",
    "\n",
    "volumes_sold1 = pd.DataFrame(volumes_sold)\n",
    "volumes_sold2 =  volumes_sold1.rename (columns ={ 0: 'Volumes Sold'})\n",
    "\n",
    "Task4 = driver.find_elements_by_xpath(\"//tbody/tr/td[5]\")\n",
    "\n",
    "for ap in Task4:\n",
    "    ac = ap.text\n",
    "    publisher.append(ac)\n",
    "\n",
    "publisher1 = pd.DataFrame(publisher)\n",
    "publisher2 = publisher1.rename(columns = { 0 : 'Publisher'})\n",
    "\n",
    "Task5 = driver.find_elements_by_xpath(\"//tbody/tr/td[6]\")\n",
    "\n",
    "for vp in Task5:\n",
    "    qf = vp.text\n",
    "    genre.append(qf)\n",
    "\n",
    "genre1 = pd.DataFrame(genre)\n",
    "genre2 = genre1.rename (columns = { 0: 'Genre'})\n",
    "\n",
    "Highest_Selling_Novels = pd.concat( [book_name2 , author_name2 , volumes_sold2 , publisher2 ,genre2]  , axis = 1)\n",
    "Highest_Selling_Novels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the details of selenium exception from guru99.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "\n",
    "#Loading Driver\n",
    "driver=webdriver.Edge(r\"C:\\Users\\PANKAJ\\Downloads\\msedgedriver.exe\")\n",
    "\n",
    "# Giving the name of website we have to  scrap\n",
    "url1 = \"https://www.guru99.com/\"\n",
    "\n",
    "#Getting Url \n",
    "driver.get(url1)\n",
    "\n",
    "time.sleep(8)\n",
    "\n",
    "\n",
    "Exception_Name = []\n",
    "Description = []\n",
    "\n",
    "Task6 = driver.find_element_by_xpath(\"//ul[@class='menu']/li[3]/a[@title='Selenium']\")\n",
    "Task6.click()\n",
    "\n",
    "Task7 = driver.find_element_by_xpath(\"//td[@class='responsivetable']/a[@title='Selenium Exception Handling (Common Exceptions List)']/strong\")\n",
    "Task7.click()\n",
    "\n",
    "Task8 = driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1] /strong\")\n",
    "\n",
    "for qm in Task8:\n",
    "    ap = qm.text\n",
    "    Exception_Name.append(ap)\n",
    "\n",
    "Exception_Name1 = pd.DataFrame(Exception_Name)\n",
    "Exception_Name2= Exception_Name1.rename(columns = { 0:'Exception Name'})\n",
    "\n",
    "Exception_Name3 =Exception_Name2.iloc[1:42]\n",
    "\n",
    "Task9 = driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2] /strong\")\n",
    "s\n",
    "for qmb in Task9:\n",
    "    apb = qmb.text\n",
    "    Description.append(apb)\n",
    "\n",
    "Description1 = pd.DataFrame(Description)\n",
    "Description2= Description1.rename(columns = { 0:'Description'})\n",
    "\n",
    "Description3 = Description2.iloc[1:42]\n",
    "\n",
    "Selenium_Exception = pd.concat([Exception_Name3,Description3 ] , axis=1)\n",
    "Selenium_Exception "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]/ strong\")\n",
    "dff[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
